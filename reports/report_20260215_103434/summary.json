{
  "generated_at": "2026-02-15T10:34:51.605439",
  "base_dir": "/net/scratch/mbax2an2/DI-engine",
  "report_dir": "/net/scratch/mbax2an2/DI-engine/reports/report_20260215_103434",
  "runs": [
    {
      "env": "pendulum",
      "algo": "r2d2",
      "prefix": "pendulum_r2d2_gtrxl_seed",
      "seed": 0,
      "log_path": "/net/scratch/mbax2an2/DI-engine/pendulum_r2d2_gtrxl_seed0/log/evaluator/evaluator_logger.txt",
      "points": [
        {
          "train_iter": 0.0,
          "reward_mean": -1713.304175
        }
      ],
      "max_score": -1713.304175
    },
    {
      "env": "pendulum",
      "algo": "r2d2",
      "prefix": "pendulum_r2d2_gtrxl_seed",
      "seed": 0,
      "log_path": "/net/scratch/mbax2an2/DI-engine/pendulum_r2d2_gtrxl_seed0_260215_100544/log/evaluator/evaluator_logger.txt",
      "points": [
        {
          "train_iter": 0.0,
          "reward_mean": -1713.304175
        },
        {
          "train_iter": 40.0,
          "reward_mean": -1437.655249
        },
        {
          "train_iter": 80.0,
          "reward_mean": -1239.435742
        },
        {
          "train_iter": 120.0,
          "reward_mean": -1260.862012
        },
        {
          "train_iter": 160.0,
          "reward_mean": -1433.373706
        },
        {
          "train_iter": 200.0,
          "reward_mean": -1677.298633
        },
        {
          "train_iter": 240.0,
          "reward_mean": -1465.799829
        },
        {
          "train_iter": 280.0,
          "reward_mean": -1519.020435
        },
        {
          "train_iter": 320.0,
          "reward_mean": -1487.399902
        },
        {
          "train_iter": 360.0,
          "reward_mean": -1452.635937
        },
        {
          "train_iter": 400.0,
          "reward_mean": -1453.80896
        },
        {
          "train_iter": 440.0,
          "reward_mean": -1448.168359
        },
        {
          "train_iter": 480.0,
          "reward_mean": -1442.091138
        },
        {
          "train_iter": 520.0,
          "reward_mean": -1438.862061
        },
        {
          "train_iter": 560.0,
          "reward_mean": -1442.37041
        },
        {
          "train_iter": 600.0,
          "reward_mean": -1438.351001
        },
        {
          "train_iter": 640.0,
          "reward_mean": -1445.599414
        },
        {
          "train_iter": 680.0,
          "reward_mean": -1429.791602
        },
        {
          "train_iter": 720.0,
          "reward_mean": -1427.678198
        },
        {
          "train_iter": 760.0,
          "reward_mean": -1430.180859
        },
        {
          "train_iter": 800.0,
          "reward_mean": -1392.250244
        },
        {
          "train_iter": 840.0,
          "reward_mean": -1367.766846
        },
        {
          "train_iter": 880.0,
          "reward_mean": -1202.78452
        },
        {
          "train_iter": 920.0,
          "reward_mean": -1300.889233
        },
        {
          "train_iter": 960.0,
          "reward_mean": -1182.097716
        },
        {
          "train_iter": 1000.0,
          "reward_mean": -1177.862327
        },
        {
          "train_iter": 1040.0,
          "reward_mean": -1191.85878
        },
        {
          "train_iter": 1080.0,
          "reward_mean": -1177.754279
        },
        {
          "train_iter": 1120.0,
          "reward_mean": -1179.849438
        },
        {
          "train_iter": 1160.0,
          "reward_mean": -1155.715842
        },
        {
          "train_iter": 1200.0,
          "reward_mean": -1167.52063
        },
        {
          "train_iter": 1240.0,
          "reward_mean": -1182.085332
        },
        {
          "train_iter": 1280.0,
          "reward_mean": -1176.943831
        },
        {
          "train_iter": 1320.0,
          "reward_mean": -1154.568371
        },
        {
          "train_iter": 1360.0,
          "reward_mean": -1117.611109
        },
        {
          "train_iter": 1400.0,
          "reward_mean": -1139.755129
        },
        {
          "train_iter": 1440.0,
          "reward_mean": -1140.379008
        },
        {
          "train_iter": 1480.0,
          "reward_mean": -1134.177928
        },
        {
          "train_iter": 1520.0,
          "reward_mean": -1115.056477
        },
        {
          "train_iter": 1560.0,
          "reward_mean": -1123.411547
        },
        {
          "train_iter": 1600.0,
          "reward_mean": -1076.276763
        },
        {
          "train_iter": 1640.0,
          "reward_mean": -1119.595966
        },
        {
          "train_iter": 1680.0,
          "reward_mean": -1065.962853
        },
        {
          "train_iter": 1720.0,
          "reward_mean": -1077.136197
        },
        {
          "train_iter": 1760.0,
          "reward_mean": -1047.860232
        },
        {
          "train_iter": 1800.0,
          "reward_mean": -1057.10596
        },
        {
          "train_iter": 1840.0,
          "reward_mean": -1095.586835
        },
        {
          "train_iter": 1880.0,
          "reward_mean": -1100.182959
        },
        {
          "train_iter": 1920.0,
          "reward_mean": -1068.745658
        },
        {
          "train_iter": 1960.0,
          "reward_mean": -1004.987986
        },
        {
          "train_iter": 2000.0,
          "reward_mean": -1047.952305
        },
        {
          "train_iter": 2040.0,
          "reward_mean": -1038.271798
        },
        {
          "train_iter": 2080.0,
          "reward_mean": -1030.44634
        },
        {
          "train_iter": 2120.0,
          "reward_mean": -1043.205765
        },
        {
          "train_iter": 2160.0,
          "reward_mean": -1032.841929
        },
        {
          "train_iter": 2200.0,
          "reward_mean": -1032.972873
        },
        {
          "train_iter": 2240.0,
          "reward_mean": -1022.401202
        },
        {
          "train_iter": 2280.0,
          "reward_mean": -1029.787881
        },
        {
          "train_iter": 2320.0,
          "reward_mean": -1041.951041
        },
        {
          "train_iter": 2360.0,
          "reward_mean": -1027.298296
        },
        {
          "train_iter": 2400.0,
          "reward_mean": -1034.75501
        },
        {
          "train_iter": 2440.0,
          "reward_mean": -1037.851081
        },
        {
          "train_iter": 2480.0,
          "reward_mean": -1031.747497
        },
        {
          "train_iter": 2520.0,
          "reward_mean": -1035.142333
        },
        {
          "train_iter": 2560.0,
          "reward_mean": -1034.560176
        },
        {
          "train_iter": 2600.0,
          "reward_mean": -1007.988986
        },
        {
          "train_iter": 2640.0,
          "reward_mean": -1010.289731
        },
        {
          "train_iter": 2680.0,
          "reward_mean": -996.112157
        },
        {
          "train_iter": 2720.0,
          "reward_mean": -1018.023202
        },
        {
          "train_iter": 2760.0,
          "reward_mean": -1004.999137
        },
        {
          "train_iter": 2800.0,
          "reward_mean": -982.939685
        },
        {
          "train_iter": 2840.0,
          "reward_mean": -1004.909326
        },
        {
          "train_iter": 2880.0,
          "reward_mean": -993.161915
        },
        {
          "train_iter": 2920.0,
          "reward_mean": -973.910249
        },
        {
          "train_iter": 2960.0,
          "reward_mean": -974.951288
        },
        {
          "train_iter": 3000.0,
          "reward_mean": -983.911876
        },
        {
          "train_iter": 3040.0,
          "reward_mean": -989.392921
        },
        {
          "train_iter": 3080.0,
          "reward_mean": -912.29822
        },
        {
          "train_iter": 3120.0,
          "reward_mean": -962.023289
        },
        {
          "train_iter": 3160.0,
          "reward_mean": -975.347513
        },
        {
          "train_iter": 3200.0,
          "reward_mean": -961.703867
        },
        {
          "train_iter": 3240.0,
          "reward_mean": -953.308316
        },
        {
          "train_iter": 3280.0,
          "reward_mean": -847.250875
        },
        {
          "train_iter": 3320.0,
          "reward_mean": -810.300868
        },
        {
          "train_iter": 3360.0,
          "reward_mean": -677.978082
        },
        {
          "train_iter": 3400.0,
          "reward_mean": -782.262747
        },
        {
          "train_iter": 3440.0,
          "reward_mean": -492.114623
        },
        {
          "train_iter": 3480.0,
          "reward_mean": -827.579931
        },
        {
          "train_iter": 3520.0,
          "reward_mean": -439.515853
        },
        {
          "train_iter": 3560.0,
          "reward_mean": -901.136913
        },
        {
          "train_iter": 3600.0,
          "reward_mean": -798.915334
        },
        {
          "train_iter": 3640.0,
          "reward_mean": -763.220386
        },
        {
          "train_iter": 3680.0,
          "reward_mean": -464.969237
        },
        {
          "train_iter": 3720.0,
          "reward_mean": -439.677298
        },
        {
          "train_iter": 3760.0,
          "reward_mean": -849.6434
        },
        {
          "train_iter": 3800.0,
          "reward_mean": -748.004725
        },
        {
          "train_iter": 3840.0,
          "reward_mean": -573.520668
        },
        {
          "train_iter": 3880.0,
          "reward_mean": -439.318987
        },
        {
          "train_iter": 3920.0,
          "reward_mean": -437.649749
        },
        {
          "train_iter": 3960.0,
          "reward_mean": -466.801276
        },
        {
          "train_iter": 4000.0,
          "reward_mean": -437.399963
        },
        {
          "train_iter": 4040.0,
          "reward_mean": -467.425111
        },
        {
          "train_iter": 4080.0,
          "reward_mean": -438.052695
        },
        {
          "train_iter": 4120.0,
          "reward_mean": -465.851148
        },
        {
          "train_iter": 4160.0,
          "reward_mean": -437.016197
        }
      ],
      "max_score": -437.016197
    },
    {
      "env": "pong",
      "algo": "r2d2",
      "prefix": "pong_r2d2_gtrxl_seed",
      "seed": 0,
      "log_path": "/net/scratch/mbax2an2/DI-engine/pong_r2d2_gtrxl_seed0_260214_225402/log/evaluator/evaluator_logger.txt",
      "points": [
        {
          "train_iter": 0.0,
          "reward_mean": -21.0
        }
      ],
      "max_score": -21.0
    },
    {
      "env": "pong",
      "algo": "r2d2",
      "prefix": "pong_r2d2_gtrxl_seed",
      "seed": 0,
      "log_path": "/net/scratch/mbax2an2/DI-engine/pong_r2d2_gtrxl_seed0_260214_225557/log/evaluator/evaluator_logger.txt",
      "points": [
        {
          "train_iter": 0.0,
          "reward_mean": -21.0
        },
        {
          "train_iter": 304.0,
          "reward_mean": -21.0
        },
        {
          "train_iter": 608.0,
          "reward_mean": -21.0
        },
        {
          "train_iter": 912.0,
          "reward_mean": -21.0
        },
        {
          "train_iter": 1216.0,
          "reward_mean": -21.0
        },
        {
          "train_iter": 1520.0,
          "reward_mean": -21.0
        },
        {
          "train_iter": 1824.0,
          "reward_mean": -21.0
        },
        {
          "train_iter": 2128.0,
          "reward_mean": -20.6
        },
        {
          "train_iter": 2432.0,
          "reward_mean": -21.0
        },
        {
          "train_iter": 2736.0,
          "reward_mean": -20.6
        },
        {
          "train_iter": 3040.0,
          "reward_mean": -17.2
        },
        {
          "train_iter": 3344.0,
          "reward_mean": 18.0
        },
        {
          "train_iter": 3648.0,
          "reward_mean": 3.0
        },
        {
          "train_iter": 3952.0,
          "reward_mean": 18.6
        },
        {
          "train_iter": 4256.0,
          "reward_mean": -0.6
        },
        {
          "train_iter": 4560.0,
          "reward_mean": -12.2
        },
        {
          "train_iter": 4864.0,
          "reward_mean": -5.6
        },
        {
          "train_iter": 5168.0,
          "reward_mean": -17.6
        },
        {
          "train_iter": 5472.0,
          "reward_mean": -8.0
        },
        {
          "train_iter": 5776.0,
          "reward_mean": -12.6
        },
        {
          "train_iter": 6080.0,
          "reward_mean": 19.6
        },
        {
          "train_iter": 6384.0,
          "reward_mean": 16.4
        },
        {
          "train_iter": 6688.0,
          "reward_mean": 11.8
        },
        {
          "train_iter": 6992.0,
          "reward_mean": 10.6
        },
        {
          "train_iter": 7296.0,
          "reward_mean": 8.8
        },
        {
          "train_iter": 7600.0,
          "reward_mean": 19.0
        },
        {
          "train_iter": 7904.0,
          "reward_mean": -11.4
        },
        {
          "train_iter": 8208.0,
          "reward_mean": 12.8
        },
        {
          "train_iter": 8512.0,
          "reward_mean": 9.2
        },
        {
          "train_iter": 8816.0,
          "reward_mean": 19.0
        },
        {
          "train_iter": 9120.0,
          "reward_mean": 12.2
        },
        {
          "train_iter": 9424.0,
          "reward_mean": 12.0
        },
        {
          "train_iter": 9728.0,
          "reward_mean": 17.6
        },
        {
          "train_iter": 10032.0,
          "reward_mean": 4.6
        },
        {
          "train_iter": 10336.0,
          "reward_mean": 12.0
        },
        {
          "train_iter": 10640.0,
          "reward_mean": 19.6
        },
        {
          "train_iter": 10944.0,
          "reward_mean": 18.2
        },
        {
          "train_iter": 11248.0,
          "reward_mean": 11.6
        },
        {
          "train_iter": 11552.0,
          "reward_mean": 18.2
        }
      ],
      "max_score": 19.6
    },
    {
      "env": "spaceinvaders",
      "algo": "r2d2",
      "prefix": "spaceinvaders_r2d2_gtrxl_seed",
      "seed": 0,
      "log_path": "/net/scratch/mbax2an2/DI-engine/spaceinvaders_r2d2_gtrxl_seed0/log/evaluator/evaluator_logger.txt",
      "points": [
        {
          "train_iter": 0.0,
          "reward_mean": 277.5
        }
      ],
      "max_score": 277.5
    },
    {
      "env": "spaceinvaders",
      "algo": "r2d2",
      "prefix": "spaceinvaders_r2d2_gtrxl_seed",
      "seed": 0,
      "log_path": "/net/scratch/mbax2an2/DI-engine/spaceinvaders_r2d2_gtrxl_seed0_260215_102631/log/evaluator/evaluator_logger.txt",
      "points": [
        {
          "train_iter": 0.0,
          "reward_mean": 277.5
        }
      ],
      "max_score": 277.5
    },
    {
      "env": "pendulum",
      "algo": "vmpo",
      "prefix": "pendulum_vmpo_gtrxl_seed",
      "seed": 0,
      "log_path": "/net/scratch/mbax2an2/DI-engine/pendulum_vmpo_gtrxl_seed0/log/evaluator/evaluator_logger.txt",
      "points": [
        {
          "train_iter": 0.0,
          "reward_mean": -1268.972803
        },
        {
          "train_iter": 790.0,
          "reward_mean": -1311.859082
        },
        {
          "train_iter": 1580.0,
          "reward_mean": -1483.227881
        },
        {
          "train_iter": 2370.0,
          "reward_mean": -1483.227881
        },
        {
          "train_iter": 3160.0,
          "reward_mean": -1483.227881
        },
        {
          "train_iter": 3950.0,
          "reward_mean": -1483.227881
        },
        {
          "train_iter": 4740.0,
          "reward_mean": -1483.227881
        },
        {
          "train_iter": 5530.0,
          "reward_mean": -1390.144458
        },
        {
          "train_iter": 6320.0,
          "reward_mean": -1479.846338
        },
        {
          "train_iter": 7110.0,
          "reward_mean": -1479.846338
        },
        {
          "train_iter": 7900.0,
          "reward_mean": -1479.846338
        },
        {
          "train_iter": 8690.0,
          "reward_mean": -651.812217
        },
        {
          "train_iter": 9480.0,
          "reward_mean": -433.478482
        },
        {
          "train_iter": 10270.0,
          "reward_mean": -650.593623
        },
        {
          "train_iter": 11060.0,
          "reward_mean": -651.215925
        },
        {
          "train_iter": 11850.0,
          "reward_mean": -464.16323
        },
        {
          "train_iter": 12640.0,
          "reward_mean": -401.820295
        },
        {
          "train_iter": 13430.0,
          "reward_mean": -403.138916
        },
        {
          "train_iter": 14220.0,
          "reward_mean": -400.909213
        },
        {
          "train_iter": 15010.0,
          "reward_mean": -399.509909
        },
        {
          "train_iter": 15800.0,
          "reward_mean": -400.224008
        },
        {
          "train_iter": 16590.0,
          "reward_mean": -197.642235
        }
      ],
      "max_score": -197.642235
    },
    {
      "env": "pong",
      "algo": "vmpo",
      "prefix": "pong_vmpo_gtrxl_seed",
      "seed": 0,
      "log_path": "/net/scratch/mbax2an2/DI-engine/pong_vmpo_gtrxl_seed0/log/evaluator/evaluator_logger.txt",
      "points": [
        {
          "train_iter": 0.0,
          "reward_mean": -21.0
        },
        {
          "train_iter": 5000.0,
          "reward_mean": -21.0
        },
        {
          "train_iter": 10000.0,
          "reward_mean": -20.625
        },
        {
          "train_iter": 15000.0,
          "reward_mean": -20.75
        },
        {
          "train_iter": 20000.0,
          "reward_mean": -19.5
        },
        {
          "train_iter": 25000.0,
          "reward_mean": -11.125
        },
        {
          "train_iter": 30000.0,
          "reward_mean": -12.75
        },
        {
          "train_iter": 35000.0,
          "reward_mean": -3.875
        },
        {
          "train_iter": 40000.0,
          "reward_mean": -2.875
        },
        {
          "train_iter": 45000.0,
          "reward_mean": -6.5
        },
        {
          "train_iter": 50000.0,
          "reward_mean": 14.25
        },
        {
          "train_iter": 55000.0,
          "reward_mean": 18.75
        },
        {
          "train_iter": 60000.0,
          "reward_mean": 2.875
        },
        {
          "train_iter": 65000.0,
          "reward_mean": 14.25
        },
        {
          "train_iter": 70000.0,
          "reward_mean": 10.0
        },
        {
          "train_iter": 75000.0,
          "reward_mean": 3.625
        },
        {
          "train_iter": 80000.0,
          "reward_mean": 12.25
        },
        {
          "train_iter": 85000.0,
          "reward_mean": 4.375
        },
        {
          "train_iter": 90000.0,
          "reward_mean": 2.125
        },
        {
          "train_iter": 95000.0,
          "reward_mean": 8.625
        },
        {
          "train_iter": 100000.0,
          "reward_mean": 16.375
        },
        {
          "train_iter": 105000.0,
          "reward_mean": 2.0
        },
        {
          "train_iter": 110000.0,
          "reward_mean": 13.875
        },
        {
          "train_iter": 115000.0,
          "reward_mean": 12.5
        },
        {
          "train_iter": 120000.0,
          "reward_mean": 19.25
        },
        {
          "train_iter": 125000.0,
          "reward_mean": 13.5
        },
        {
          "train_iter": 130000.0,
          "reward_mean": 4.625
        },
        {
          "train_iter": 135000.0,
          "reward_mean": -0.375
        },
        {
          "train_iter": 140000.0,
          "reward_mean": -0.5
        },
        {
          "train_iter": 145000.0,
          "reward_mean": -0.5
        },
        {
          "train_iter": 150000.0,
          "reward_mean": -0.5
        },
        {
          "train_iter": 155000.0,
          "reward_mean": -6.5
        },
        {
          "train_iter": 160000.0,
          "reward_mean": -0.625
        },
        {
          "train_iter": 165000.0,
          "reward_mean": -13.125
        },
        {
          "train_iter": 170000.0,
          "reward_mean": -15.25
        },
        {
          "train_iter": 175000.0,
          "reward_mean": -15.0
        },
        {
          "train_iter": 180000.0,
          "reward_mean": -10.375
        },
        {
          "train_iter": 185000.0,
          "reward_mean": -9.75
        },
        {
          "train_iter": 190000.0,
          "reward_mean": 4.625
        },
        {
          "train_iter": 195000.0,
          "reward_mean": -0.25
        },
        {
          "train_iter": 200000.0,
          "reward_mean": -11.0
        },
        {
          "train_iter": 205000.0,
          "reward_mean": -10.625
        },
        {
          "train_iter": 210000.0,
          "reward_mean": -19.5
        },
        {
          "train_iter": 215000.0,
          "reward_mean": -15.375
        },
        {
          "train_iter": 220000.0,
          "reward_mean": -14.75
        },
        {
          "train_iter": 225000.0,
          "reward_mean": 15.5
        },
        {
          "train_iter": 230000.0,
          "reward_mean": -5.625
        },
        {
          "train_iter": 235000.0,
          "reward_mean": -20.375
        },
        {
          "train_iter": 240000.0,
          "reward_mean": -16.625
        },
        {
          "train_iter": 245000.0,
          "reward_mean": -17.75
        },
        {
          "train_iter": 250000.0,
          "reward_mean": -9.25
        },
        {
          "train_iter": 255000.0,
          "reward_mean": -18.625
        },
        {
          "train_iter": 260000.0,
          "reward_mean": -18.375
        },
        {
          "train_iter": 265000.0,
          "reward_mean": -15.625
        },
        {
          "train_iter": 270000.0,
          "reward_mean": -6.5
        },
        {
          "train_iter": 275000.0,
          "reward_mean": -13.375
        },
        {
          "train_iter": 280000.0,
          "reward_mean": -17.75
        },
        {
          "train_iter": 285000.0,
          "reward_mean": -13.75
        },
        {
          "train_iter": 290000.0,
          "reward_mean": -15.125
        },
        {
          "train_iter": 295000.0,
          "reward_mean": -16.25
        },
        {
          "train_iter": 300000.0,
          "reward_mean": -19.125
        },
        {
          "train_iter": 305000.0,
          "reward_mean": -20.0
        }
      ],
      "max_score": 19.25
    },
    {
      "env": "pong",
      "algo": "vmpo",
      "prefix": "pong_vmpo_gtrxl_seed",
      "seed": 0,
      "log_path": "/net/scratch/mbax2an2/DI-engine/pong_vmpo_gtrxl_seed0_260215_094909/log/evaluator/evaluator_logger.txt",
      "points": [
        {
          "train_iter": 0.0,
          "reward_mean": -21.0
        }
      ],
      "max_score": -21.0
    },
    {
      "env": "spaceinvaders",
      "algo": "vmpo",
      "prefix": "spaceinvaders_vmpo_gtrxl_seed",
      "seed": 0,
      "log_path": "/net/scratch/mbax2an2/DI-engine/spaceinvaders_vmpo_gtrxl_seed0/log/evaluator/evaluator_logger.txt",
      "points": [
        {
          "train_iter": 0.0,
          "reward_mean": 285.0
        },
        {
          "train_iter": 1024.0,
          "reward_mean": 228.75
        },
        {
          "train_iter": 2048.0,
          "reward_mean": 233.125
        },
        {
          "train_iter": 3072.0,
          "reward_mean": 184.375
        },
        {
          "train_iter": 4096.0,
          "reward_mean": 125.0
        },
        {
          "train_iter": 5120.0,
          "reward_mean": 256.25
        },
        {
          "train_iter": 6144.0,
          "reward_mean": 257.5
        }
      ],
      "max_score": 285.0
    }
  ],
  "max_scores": {
    "pendulum": {
      "r2d2": -437.016197,
      "vmpo": -197.642235
    },
    "pong": {
      "r2d2": 19.6,
      "vmpo": 19.25
    },
    "spaceinvaders": {
      "r2d2": 277.5,
      "vmpo": 285.0
    }
  }
}